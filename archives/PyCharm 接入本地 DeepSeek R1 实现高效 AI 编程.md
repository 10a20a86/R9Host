# PyCharm 接入本地 DeepSeek R1 实现高效 AI 编程

大家好，我是六哥，欢迎来到今天的技术分享！今天我将为大家带来一个超实用的教程，教你如何使用 PyCharm 接入 DeepSeek R1 实现 AI 编程。即使你是编程小白，也能轻松上手，话不多说，让我们开始吧！

## 一、为什么选择本地搭建 DeepSeek R1 模型？

在开始搭建之前，先和大家聊聊这样做的好处，让你明白为什么值得花时间来尝试。

### 1. 高效学习与知识库管理
在本地搭建大模型，不仅能方便你管理个人知识库，还能极大地提升编程学习效率，无论是 Python、Java 还是其他编程语言，都能轻松应对。编程就像是学习做事的思路和逻辑，既重要又有趣，而 DeepSeek R1 能成为你学习路上的得力助手。

### 2. 零成本搭建
DeepSeek 最近开源了推理模型 R1，完全免费，性能还非常强劲。我们使用的 Python 开发环境是 PyCharm 社区版，同样免费，我自己使用社区版已经超过 10 年了，稳定又好用。另外，推荐的插件 CodeGPT 也是免费的，而且 UI 设计简洁美观，用起来非常舒服。总结来说，按照本文的方法搭建，不需要花一分钱，真正的零成本上手！

### 3. 低配置也能流畅运行
考虑到大部分朋友的电脑配置，我在搭建方法上做了优化，将电脑配置要求降到最低。就算是普通电脑，也能飞速运行 DeepSeek R1，不用担心卡顿问题，具体配置和操作方法，我会在后面详细介绍。

## 二、框架选择

本次搭建的框架组合是：DeepSeek - r1:1.5b + PyCharm 专业版 + CodeGPT 插件。

DeepSeek - r1 一共有 7 个不同版本，随着尺寸参数变大，对电脑的要求也会提高，本地回复延时也会变长（因为大参数尺寸推理时间会更长）。对于没有大显存 GPU 的朋友，强烈推荐安装 1.5b 尺寸的版本，这个版本普通电脑无 GPU 也能流畅运行，延时几乎在 1 - 2 秒。而且，DeepSeek - r1 能爆火出圈的一个重要原因就是，小尺寸模型的回答质量也很高，即便 1.5b 如此小的参数尺寸也不例外。

简单介绍一下 DeepSeek - R1，它回复问题主要包括两部分：思考 (Thinking) 和 Answer（正式回答），在每次正式回答前，会有一个很长的思考链。之前的大模型在小尺寸参数（如 1.5b）回复 Token 有些简短，质量一般，但是这次 DeepSeek - r1:1.5b 解决了回复 Token 数过短，效果不好的难题。

![DeepSeek R1 示例](https://bbtdd.com/img/3097505264121165.webp)

了解了框架选择的原因，下面就进入激动人心的搭建步骤环节！

## 三、详细搭建步骤

为了让完全未接触编程的朋友也能顺利复现，我会把步骤写得尽可能细致，大家跟着做就好啦！

### 1. 安装 PyCharm
PyCharm 下载后，基本都是一路点击下一步，按照默认设置安装就行，这里就不再赘述。

### 2. 下载 ollama
安装 deepseek - r1:1.5b，在我的公众号后台回复“Ollama 离线安装包”，获取 ollama 软件。

执行命令：`ollama pull deepseek - r1:1.5b`

就能直接把它下载到自己的电脑，下载完成就安装好了，非常方便。

![Ollama 安装](https://bbtdd.com/img/712119498.webp)

下载安装后打开软件，输入 `ollama list` 可以查看当前安装的本地大模型，刚安装 ollama 时执行这条命令应该是空的。

![Ollama 列表](https://bbtdd.com/img/92094114602.webp)

### 3. 接入到 PyCharm
首先下载插件 CodeGPT，打开第一步安装的 PyCharm，找到文件 (File) -> 设置 (Settings) -> 插件 (Plugins)，输入 CodeGPT，点击安装 (Install) 即可。

![CodeGPT 安装](https://bbtdd.com/img/481556198603.webp)

安装后在工具 (Tools) 下会出现 CodeGPT，点击 Providers，找到 Ollama (Local)，再到对应位置选择刚刚安装的 deepseek - r1:1.5b，点击 OK 就大功告成了。

![CodeGPT 设置](https://bbtdd.com/img/4223802520.webp)

现在，就可以愉快地在 PyCharm 中使用 DeepSeek - r1 加速编程学习了！左侧是代码编辑界面，右侧是 r1 大模型，直接对话式提问，省去了来回切换不同页面的麻烦。大家可以感受一下 DeepSeek - r1:1.5b 大模型的回复延时，几乎 1 秒钟就能响应，我的测试电脑是 pro - m1，这响应速度相当给力！再看看回答效果。

![DeepSeek R1 回复](https://bbtdd.com/img/07704089170785.webp)

另外，CodeGPT 插件显示的 Tokens 数只是一个数字统计，不会产生任何费用，因为使用的是本地自己电脑的算力，大家可以放心使用。

## 四、总结

通过今天的教程，我们成功在本地运行了大模型，实现了免费、便捷的编程学习和个人知识管理。总结一下本次搭建的要点：

1. **选型推荐**：deepseek - r1:1.5b + PyCharm 社区版 + CodeGPT 插件，这个组合性价比超高，适合大多数人。
2. **便捷交互**：在 PyCharm 右侧直接对话 DeepSeek - R1，快速辅助编程，提高学习和工作效率。
3. **快速响应**：几乎 1 - 2 秒响应，完全本地快速运行，无额外费用，让你用得省心又省力。

👉 [WildCard | 一分钟注册，轻松订阅海外线上服务](https://bbtdd.com/WildCard)

如果这篇文章对你有帮助，希望你能给我点个关注，来个三连击：点赞、转发和在看。要是能再给我加个⭐️，那就太感谢啦！我们下篇文章再见！